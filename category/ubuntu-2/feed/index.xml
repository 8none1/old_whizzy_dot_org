<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Ubuntu &#8211; whizzy.org</title>
	<atom:link href="/category/ubuntu-2/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>On code and gadgets.</description>
	<lastBuildDate>Wed, 14 Jul 2021 11:40:11 +0000</lastBuildDate>
	<language>en-GB</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.7.2</generator>
	<item>
		<title>Double helping of Pi Hole</title>
		<link>/2021/01/02/double-helping-of-pi-hole/</link>
					<comments>/2021/01/02/double-helping-of-pi-hole/#comments</comments>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Sat, 02 Jan 2021 17:45:02 +0000</pubDate>
				<category><![CDATA[linux]]></category>
		<category><![CDATA[RaspberryPi]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=1020</guid>

					<description><![CDATA[Improve the performance of Pi Hole by running it on a more powerful computer. Durr.]]></description>
										<content:encoded><![CDATA[
<p>In <a href="https://latenightlinux.com/late-night-linux-episode-100/">episode 100 of Late Night Linux</a> I talked a little bit about trying out <a href="https://pi-hole.net/">Pi Hole</a> and <a href="https://adguard.com/en/welcome.html">AdGuard</a> to replace my home grown ad blocker based on <a href="http://www.thekelleys.org.uk/dnsmasq/doc.html">dnsmasq</a> and a massive hosts file.</p>



<p>I came down in favour of Pi Hole for a couple of reasons but the deciding factor was that Pi Hole felt a bit more open and that it was built on top of <code>dnsmasq</code> which allowed me to reuse config for TFTP which netboots some devices which needed it.</p>



<p>Now that I&#8217;ve been using Pi Hole for a few months I have a much better understanding of its limitations and the big one for me is performance. Not the performance when servicing DNS requests but performance when querying the stats data, when reloading block lists and when enabling and disabling certain lists. I suspect a lot of the problems I was having is down to flaky SD cards.</p>



<p>I fully expect that for most people this will never be a problem, but for me it was an itch I wanted to scratch, so here&#8217;s what I did:</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img loading="lazy" width="341" height="581" src="/wp-content/uploads/2021/01/Double-Pi-Hole.png" alt="" class="wp-image-1021" srcset="/wp-content/uploads/2021/01/Double-Pi-Hole.png 341w, /wp-content/uploads/2021/01/Double-Pi-Hole-176x300.png 176w" sizes="(max-width: 341px) 100vw, 341px" /></figure></div>



<p>Through the actually quite generous <a href="https://developer.amazon.com/en-US/alexa/alexa-skills-kit/new/aws-promotional-credits">Amazon Alexa AWS Credits promotion</a> I have free money to spend on AWS services, so I spun up a <code>t2.micro</code> EC2 instance (1 vCPU, 1GB RAM &#8211; approx £10 a month) running Ubuntu.</p>



<p>I installed Pi Hole on that instance along with Wireguard which connects it back to my local network at home.  I used <a href="https://www.linode.com/docs/guides/set-up-wireguard-vpn-on-ubuntu/">this guide from Linode</a> to get Wireguard set up.  </p>



<p>The Pi Hole running in AWS hosts the large block files and is configured with a normal upstream DNS server as its upstream (I&#8217;m using Cloudflare).</p>



<figure class="wp-block-image size-large"><img loading="lazy" width="484" height="627" src="/wp-content/uploads/2021/01/image-2.png" alt="" class="wp-image-1024" srcset="/wp-content/uploads/2021/01/image-2.png 484w, /wp-content/uploads/2021/01/image-2-232x300.png 232w" sizes="(max-width: 484px) 100vw, 484px" /><figcaption>Pi Hole running in AWS configured with Cloudflare as its upstream DNS</figcaption></figure>



<p>I use three Ad block lists:</p>



<ul><li><code>OISD:</code> <a href="https://dbl.oisd.nl/">https://dbl.oisd.nl/</a></li><li><code>Wally3k:</code> <a href="https://v.firebog.net/hosts/static/w3kbl.txt">https://v.firebog.net/hosts/static/w3kbl.txt</a></li><li><code>Polish Filters Team: </code><a href="https://raw.githubusercontent.com/PolishFiltersTeam/KADhosts/master/KADhosts_without_controversies.txt">https://raw.githubusercontent.com/PolishFiltersTeam/KADhosts/master/KADhosts_without_controversies.txt</a></li></ul>



<figure class="wp-block-image size-large"><img loading="lazy" width="1000" height="389" src="/wp-content/uploads/2021/01/image-1.png" alt="" class="wp-image-1023" srcset="/wp-content/uploads/2021/01/image-1.png 1000w, /wp-content/uploads/2021/01/image-1-300x117.png 300w, /wp-content/uploads/2021/01/image-1-768x299.png 768w, /wp-content/uploads/2021/01/image-1-720x280.png 720w" sizes="(max-width: 1000px) 100vw, 1000px" /></figure>



<p>Pi Hole running on a <code>t2.micro</code> instance is really speedy.  I can reload the block list in a matter of seconds (versus minutes on the Pi) and querying the stats database no longer locks up and crashes Pi Hole&#8217;s management engine FTL.</p>



<p>The Pi Hole running on my LAN is configured to use the above AWS based Pi Hole as its upstream DNS server and also has a couple of additional block lists for <a href="https://raw.githubusercontent.com/8none1/pihole-blocklists/main/youtube/hosts">YouTube</a> and <a href="https://raw.githubusercontent.com/llacb47/mischosts/master/social/tiktok-block">TikTok</a>.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img loading="lazy" width="1000" height="389" src="/wp-content/uploads/2021/01/image.png" alt="" class="wp-image-1022" srcset="/wp-content/uploads/2021/01/image.png 1000w, /wp-content/uploads/2021/01/image-300x117.png 300w, /wp-content/uploads/2021/01/image-768x299.png 768w, /wp-content/uploads/2021/01/image-720x280.png 720w" sizes="(max-width: 1000px) 100vw, 1000px" /></figure></div>



<p>This allows me use Pi Hole on a Pi as the DHCP server on my LAN and benefit from the GUI to configure things.  I can quickly and easily block YouTube when the kids have done enough and won&#8217;t listen to reason and the heavy lifting of bulk ad blocking is done on an AWS EC2 instance.  The Pi on the LAN will cache a good amount of DNS and so everything whizzes along quickly.</p>



<p>Pi Hole on the LAN has a block list of about 3600 hosts, whereas the version running in AWS has over 1.5 million.</p>



<p>All things considered I&#8217;m really happy with Pi Hole and the split-load set up I have now makes it even easier to live with.  I would like to see an improved Pi Hole API for enabling and disabling specific Ad lists so that I can make it easier to automate (e.g. unblock YouTube for two hours on a Saturday morning).  I think that will come in time.  The split-load set up also allows for easy fallback should the AWS machine need maintenance &#8211; it would be nice to have a &#8220;DNS server of last resort&#8221; in Pi Hole to make that automatic.  Perhaps it already does, I should investigate.</p>



<p>Why not just run Pi Hole on a more powerful computer in the first place? That would be too easy.</p>



<p>If you fancy trying out Pi Hole in the cloud or just playing with Wireguard you can get $100 free credit with Linode with the Late Night Linux referral code: <a href="https://linode.com/latenightlinux">https://linode.com/latenightlinux</a></p>



<p></p>
]]></content:encoded>
					
					<wfw:commentRss>/2021/01/02/double-helping-of-pi-hole/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
			</item>
		<item>
		<title>DNS over HTTPS in a snap</title>
		<link>/2019/07/16/dns-over-https-in-a-snap/</link>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Tue, 16 Jul 2019 20:07:44 +0000</pubDate>
				<category><![CDATA[IoT]]></category>
		<category><![CDATA[linux]]></category>
		<category><![CDATA[RaspberryPi]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">/?p=970</guid>

					<description><![CDATA[Background Story With the recent news about the ISP UK association proposing Mozilla [&#8230;]]]></description>
										<content:encoded><![CDATA[
<h2>Background Story</h2>



<p>With the recent news about the ISP UK association proposing Mozilla as &#8220;<a href="https://www.ispa.org.uk/ispa-announces-finalists-for-2019-internet-heroes-and-villains-trump-and-mozilla-lead-the-way-as-villain-nominees/">Internet villain of the year</a>&#8221; for enabling DNS over HTTPS (and subsequently changing their mind and dropping the whole category of villain of the year.  Good move I think.) I figured it was probably about time that I looked at enabling DoH at home.</p>



<p>Cloudflare have a suite of open source tools called <a href="https://github.com/cloudflare/cloudflared/">cloudflared</a> which has, among other things, a DNS over HTTPS proxy.  By default it points at their 1.1.1.1 service, but you can change that if you want to.  Note, at the time of writing there is a <a href="https://github.com/cloudflare/cloudflared/issues/113">bug</a> which seems to stop Google&#8217;s DNS service working.  If you&#8217;re looking to stop people seeing your DNS traffic then Google probably isn&#8217;t the right DNS service to use anyway.</p>



<figure class="wp-block-image size-large"><img loading="lazy" width="353" height="469" src="/wp-content/uploads/2019/07/proxy-dns.jpg" alt="" class="wp-image-972" srcset="/wp-content/uploads/2019/07/proxy-dns.jpg 353w, /wp-content/uploads/2019/07/proxy-dns-226x300.jpg 226w" sizes="(max-width: 353px) 100vw, 353px" /></figure>



<p>I already have dnsmasq running as my DNS server and I have quite a lot of config which I wanted to keep (e.g. adblocking) so I figured I would add cloudflared&#8217;s proxy-dns alongside dnsmasq and have dnsmasq use proxy-dns as it&#8217;s upstream server, which would in turn pass the DNS lookups to 1.1.1.1 over HTTPS.  dnsmasq would then cache the results locally.</p>



<p>So far, so good.  I&#8217;d built cloudflared on my desktop to test it, now I wanted to move it on to the Raspberry Pi, run it as a service, and ideally have a package so that I didn&#8217;t have to mess around rebuilding it in loads of places if I wanted to move to a different box.</p>



<h2>Make a snap</h2>



<p>Making a snap of proxy-dns would give the the package I wanted, and could allow me to run proxy-dns as a daemon with two words in the YAML.  Snapcraft&#8217;s <a href="https://snapcraft.io/build">build service</a> would build me an ARM binary, as well as loads of others, for free.</p>



<p>I downloaded the source for <a href="https://github.com/cloudflare/cloudflared">cloudflared</a> and added three files:</p>



<ol><li>A <a href="https://github.com/8none1/cloudflaredohsnap/blob/master/snapcraft.yaml">snapcraft.yaml</a> which describes how to build cloudflared and sets it to be run as a daemon</li><li>A <a href="https://github.com/8none1/cloudflaredohsnap/blob/master/snap/hooks/configure">configure hook</a> which lets me set some config options</li><li>A <a href="https://github.com/8none1/cloudflaredohsnap/blob/master/launcher/launcher">launcher script</a> which sets the config at run time</li></ol>



<p>None of these are very complicated, as you can see.  Hat-tip to <a href="https://twitter.com/popey">Popey</a> for help with the snapcraft.yaml.</p>



<p>The I pushed these back to my project on <a href="https://github.com/8none1/cloudflaredohsnap">GitHub</a> and added that project to the <a href="https://snapcraft.io/build">Snapcraft.io build service</a>.  Now, whenever I push a new change back to GitHub the snap will get rebuilt <strong>automatically</strong> and uploaded to the store! All I would need to do is a snap refresh and I&#8217;d be upgraded to the latest version. All my requirements solved in one place.</p>



<h2>How to use the snap</h2>



<p>If your Pi is running snapd, it&#8217;s dead easy (e.g. Ubuntu MATE or Ubuntu Core):</p>



<pre class="wp-block-preformatted">sudo snap install cloudflaredoh --edge</pre>



<p>The snap is currently in the edge channel, meaning it&#8217;s not ready for the main stage just yet.  Once I&#8217;ve spent a bit more time on it, I will move it to stable.</p>



<pre class="wp-block-preformatted">sudo snap set cloudflaredoh address=127.0.0.1<br>sudo snap set cloudflaredoh port=5053</pre>



<p>Configure proxy-dns to listen on 127.0.0.1.  If you want it to answer DNS queries from other computers on your network try either the IP address of the box, or just 0.0.0.0 to listen on all interfaces.  It will also configure proxy-dns to listen on port 5053.  If you want it to answer DNS queries from other computers on your network, use the default DNS port of 53.</p>



<pre class="wp-block-preformatted">sudo snap get cloudflaredoh</pre>



<p>This will show you the currently set config options.</p>



<pre class="wp-block-preformatted">sudo snap restart cloudflaredoh</pre>



<p>Restart proxy-dns and use the new config.</p>



<p>Now you can use something like nslookup to query the DNS server and make sure it&#8217;s doing what you expected.</p>



<h2>10 Steps To DNS-over-HTTPS</h2>



<ol><li>Get a Raspberry Pi</li><li>Download Ubuntu Core and write it to an SD card</li><li>Put the SD card in your Pi and boot it</li><li>Set up the network on Ubuntu Core (tip: register for an <a href="https://login.ubuntu.com/+login">Ubuntu One</a> account first)</li><li>sudo snap install cloudflaredoh</li><li>sudo snap set cloudflaredoh address=0.0.0.0</li><li>sudo snap set cloudflaredoh port=53</li><li>sudo snap restart cloudflaredoh</li><li>Configure your client&#8217;s DNS server as the IP address of your Pi</li><li>Have a cup of tea</li></ol>



<h2>Update 2019-08-01</h2>



<p>I&#8217;ve got a new Github repo set up with an improved snapcraft.yaml which pulls directly from the upstream project.  I&#8217;m aiming to get this hooked up to the Snapcraft build service so that we can package the latest version automatically.  More on this later.  In the meantime, you can clone this and build the latest version yourself:</p>



<p><a href="https://github.com/8none1/cloudflarednsproxy">https://github.com/8none1/cloudflarednsproxy</a></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Ubuntu Developer Desktop Survey 2019</title>
		<link>/2019/05/07/ubuntu-developer-desktop-survey-2019/</link>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Tue, 07 May 2019 17:53:31 +0000</pubDate>
				<category><![CDATA[Making the world a better place]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=962</guid>

					<description><![CDATA[It’s clear that a lot of people develop software using Ubuntu. What’s less [&#8230;]]]></description>
										<content:encoded><![CDATA[
<p>It’s clear that a lot of people develop software using Ubuntu. What’s less clear is exactly what sort of software is being built. We see reports of people developing Linux apps, Android apps, web services, self driving cars… the list is huge. We need to get better clarity; to understand how that relates to Ubuntu desktop.</p>



<p>We can get some reasonable insights from the <a href="https://insights.stackoverflow.com/survey/2019">Stack Overflow Developer Survey</a>, but I&#8217;m keen to really dig down in to the Ubuntu community specifically.</p>



<p>When I was chatting with <a href="https://bartongeorge.io/">Barton George</a> a few weeks back he expressed the same interest;  what <em>are</em> people doing with the <a href="https://www.dell.com/learn/us/en/555/campaigns/xps-linux-laptop_us">Sputnik</a> machines from Dell?  We want to learn more about the sorts of software projects that you&#8217;re working on so that we can make the Ubuntu developer experience as good as possible.</p>



<p>To that end we put together the <a href="http://desktopdevelopersurvey2019.ubuntu.com/">Ubuntu Developer Desktop Survey</a> to help us understand more about what you’re doing and how you’re doing it. This survey is aimed primarily at people who are using Ubuntu to develop software targeting any platform. It doesn’t matter if you do that at work, at home, at school – if you’re building software then we’re glad to hear from you. To be clear: this doesn’t mean we’re abandoning our mantra of Ubuntu being for human beings, software developers are human beings too. Right now I want to get a better view in to what software developers are doing.</p>



<p>The survey will close on Friday 31st May 2019 and we will publish the results very shortly afterwards.  We&#8217;ll then follow that up with some further analysis and some ideas as to how this will influence the desktop product roadmap in the future.  Please take this opportunity to help shape Ubuntu for the better.</p>



<p>You can find the survey here:</p>



<p style="text-align:center"><a href="http://desktopdevelopersurvey2019.ubuntu.com/">http://desktopdevelopersurvey2019.ubuntu.com/</a></p>



<p>You don’t need to register or sign in to complete the form.</p>



<p></p>



<p></p>



<p></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>What to do with Unity 8 now</title>
		<link>/2016/10/14/what-to-do-with-unity-8-now/</link>
					<comments>/2016/10/14/what-to-do-with-unity-8-now/#comments</comments>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Fri, 14 Oct 2016 13:09:24 +0000</pubDate>
				<category><![CDATA[Making the world a better place]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=786</guid>

					<description><![CDATA[As you&#8217;re probably aware Ubuntu 16.10 was released yesterday and brings with it [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>As you&#8217;re probably aware Ubuntu 16.10 was released yesterday and brings with it the Unity 8 desktop session as a preview of what&#8217;s being worked on right now and a reflection of the current state of play.</p>
<p>You might have already logged in and kicked the proverbial tyres.  If not I would urge you to do so.  Please take the time to install a couple of apps as laid out here:</p>
<p><a href="http://insights.ubuntu.com/2016/10/13/unity-8-preview-session-in-ubuntu-16-10-yakkety-yak/">http://insights.ubuntu.com/2016/10/13/unity-8-preview-session-in-ubuntu-16-10-yakkety-yak/</a></p>
<p>The main driver for getting Unity 8 in to 16.10 was the chance to get it in the hands of users so we can get feedback and bug reports.  If you find something doesn&#8217;t work, please, log a bug.  We don&#8217;t monitor every forum or comments section on the web so the absolute best way to provide your feedback to people who can act on it is a bug report with clear steps on how to reproduce the issue (in the case of crashes) or an explanation of why you think a particular behaviour is wrong.  This is how you get things changed or fixed.</p>
<p>You can contribute to Ubuntu by simply playing with it.</p>
<p>Read about logging bugs in Ubuntu here: <a href="https://help.ubuntu.com/community/ReportingBugs">https://help.ubuntu.com/community/ReportingBugs</a></p>
<p>And when you are ready to log a bug, log it against Unity 8 here: <a href="https://bugs.launchpad.net/ubuntu/+source/unity8">https://bugs.launchpad.net/ubuntu/+source/unity8</a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>/2016/10/14/what-to-do-with-unity-8-now/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>Unity 7 Low Graphics Mode</title>
		<link>/2016/09/01/unity-7-low-graphics-mode/</link>
					<comments>/2016/09/01/unity-7-low-graphics-mode/#comments</comments>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Thu, 01 Sep 2016 10:43:23 +0000</pubDate>
				<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=753</guid>

					<description><![CDATA[Unity 7 has had a low graphics mode for a long time but [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>Unity 7 has had a low graphics mode for a long time but recently we&#8217;ve been making it better.</p>
<p><a href="https://wiki.ubuntu.com/hikiko">Eleni</a> has been making improvements to reduce the amount of visual effects that are seen while running in low graphics mode.  At a high level this includes things like:</p>
<ul>
<li>Reducing the amount of animation in elements such as the window switcher, launcher and menus (in some cases down to zero)</li>
<li>Removing blur and fade in/out</li>
<li>Reducing shadows</li>
</ul>
<p>The result of these changes will be beneficial to people running Ubuntu in a virtual machine (where hardware 3D acceleration is not available) and for remote-control of desktops with VNC, RDP etc.</p>
<p>Low graphics mode should enable itself when it detects certain GL features are not available (e.g. in a virtualised environment) but there are times when you might want to force it on.  Here&#8217;s how you can force low graphics mode on 16.04 LTS (Xenial) :</p>
<ol>
<li>nano ~/.config/upstart/lowgfx.conf</li>
<li>Paste this into it:</li>
</ol>
<pre>start on starting unity7
pre-start script
    initctl set-env -g UNITY_LOW_GFX_MODE=1
end script</pre>
<ol start="3">
<li>Log out and back in</li>
</ol>
<p>If you want to stop using low graphics comment out the initctl line by placing a &#8216;#&#8217; at the start of the line.</p>
<p>This hack won&#8217;t work in 16.10 Yakkety because we&#8217;re moving to systemd for the user session.  I&#8217;ll write up some instructions for 16.10 once it&#8217;s available.</p>
<p>Here&#8217;s a quick video of some of the effects in low graphics mode:</p>
<p><iframe loading="lazy" src="//www.youtube.com/embed/gWUyP-oTRVg" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>/2016/09/01/unity-7-low-graphics-mode/feed/</wfw:commentRss>
			<slash:comments>4</slash:comments>
		
		
			</item>
		<item>
		<title>Online searches in the dash to be off by default.</title>
		<link>/2015/12/10/online-searches-in-the-dash-to-be-off-by-default/</link>
					<comments>/2015/12/10/online-searches-in-the-dash-to-be-off-by-default/#comments</comments>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Thu, 10 Dec 2015 10:53:10 +0000</pubDate>
				<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=721</guid>

					<description><![CDATA[Scopes are a leading feature of the Ubuntu Phone and of Unity 8 [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><span style="font-weight: 400;">Scopes are a leading feature of the Ubuntu Phone and of Unity 8 in general.  That concept, the story of scopes, started out in Unity 7 and in 12.10 when we added results from online searches to the dash home screen. </span></p>
<p><span style="font-weight: 400;">Well, we’re making some changes to the Unity 7 Dash searches in 16.04 LTS.  On Unity 8 the Scopes concept has evolved into something which gives the user finer control over what is searched and provides more targeted results.  This functionality cannot be added into Unity 7 and so we’ve taken the decision to gracefully retire some aspects of the Unity 7 online search features.</span></p>
<h3><span style="font-weight: 400;">What is changing?</span></h3>
<p><span style="font-weight: 400;">First of all online search will be off by default.  This means that out-of-the-box none of your search terms will leave your computer.  You can toggle this back on through the Security &amp; Privacy option in System Settings.  Additionally, if you do toggle this back on then results from Amazon &amp; Skimlinks will remain off by default.  You can toggle them back on if you wish.  Further, the following scopes will be retired from the default install and moved to the Universe repository for 16.04 LTS onwards:</span></p>
<ol>
<ol>
<li style="font-weight: 400;"><span style="font-weight: 400;">Audacious</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Clementine</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">gmusicbrowser</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Gourmet</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Guayadeque</span></li>
<li style="font-weight: 400;"><span style="font-weight: 400;">Musique</span></li>
</ol>
</ol>
<p><span style="font-weight: 400;">The Music Store will be removed completely for 16.04 LTS onwards.</span></p>
<h3><span style="font-weight: 400;">Why now?</span></h3>
<p><span style="font-weight: 400;">By making these changes now we can better manage our development priorities, servers, network bandwidth etc throughout the LTS period. We allow ourselves more freedom to make changes without further affecting the LTS release (e.g SRUs), specifically we can better manage the eventual transition to Unity 8 and not have to maintain two sets of scope infrastructure for the duration of the LTS support period of five years.</span></p>
<h3><span style="font-weight: 400;">What about previous supported releases?</span></h3>
<p><span style="font-weight: 400;">Search results being off by default will not affect previous releases or upgrades, only new installs (i.e. we will not touch your existing settings).  Changes to search results from Amazon &amp; Skimlinks will also only affect 16.04 and beyond.  The removal of the Music Store will be SRU’d back to older supported releases and the option will be removed from the Dash.</span></p>
<h3><span style="font-weight: 400;">When will this happen?</span></h3>
<p><span style="font-weight: 400;">We’re preparing the make the changes in the archive, to Unity 7 and to the Online Search servers right now.  This will take a little while to test and roll out.  We’ll let you know once all the changes are in Xenial.</span></p>
]]></content:encoded>
					
					<wfw:commentRss>/2015/12/10/online-searches-in-the-dash-to-be-off-by-default/feed/</wfw:commentRss>
			<slash:comments>33</slash:comments>
		
		
			</item>
		<item>
		<title>My first 10 years with Ubuntu</title>
		<link>/2015/10/14/10-years-with-ubuntu/</link>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Wed, 14 Oct 2015 08:00:57 +0000</pubDate>
				<category><![CDATA[linux]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=685</guid>

					<description><![CDATA[Today I have had a Launchpad account for ten years! I got started [&#8230;]]]></description>
										<content:encoded><![CDATA[<p><a href="http://whizzy.org/wp-content/uploads/2015/10/IMG_1220.jpg"><img loading="lazy" class="alignleft wp-image-691" src="http://whizzy.org/wp-content/uploads/2015/10/IMG_1220.jpg" alt="IMG_1220" width="799" height="132" srcset="/wp-content/uploads/2015/10/IMG_1220.jpg 1005w, /wp-content/uploads/2015/10/IMG_1220-300x50.jpg 300w, /wp-content/uploads/2015/10/IMG_1220-768x127.jpg 768w" sizes="(max-width: 799px) 100vw, 799px" /></a></p>
<p>Today I have had a <a href="https://launchpad.net/~willcooke">Launchpad account</a> for ten years!</p>
<p>I got started out on this road around 1992.  I remember the day <a href="http://www.kryogenix.org/">Stuart</a> got a PC and installed Minix on it.  That box was biege, naturally, was about 3 feet square and constructed from inch thick iron plate.  Minix was totally alien when compared to the Acorn <a href="https://en.wikipedia.org/wiki/Acorn_MOS">MOS</a> and <a href="https://en.wikipedia.org/wiki/RISC_OS">RISCOS</a> powered machines I&#8217;d used until then, and absolutely intriguing.</p>
<p>A few years later at university I encountered VAX/VMS and Sun SPARCstations and The Internet and <a href="https://en.wikipedia.org/wiki/Surfers_(talker)">Surfers</a> and Mozilla and a Gopher connected Coke machine.</p>
<p>Then out into the big wide world of work and run-ins with AS400 and RS/6000s running AIX.  During this time I started seeing more and more Red Hat in places where there once would have been the more established players, providing email and web servers.  The fascination with *nix was always there and I started using Red Hat at home for fun.</p>
<p>I quickly ran into frustrations with RPMs and Stuart, always a source of wisdom, suggested I try Debian.</p>
<p>Dpkg made my life a whole lot easier and I started using Debian as my default OS for everything. Pretty soon after that I found myself compiling kernels, modules and software packages because I needed or wanted something in a newer version.  Coupled with the availability of cheap unbranded webcams, sound cards, network cards, TV cards etc and a strong desire to make these things work with Linux meant that I had found a wonderful way to stay up until 4 in the morning getting more and more frustrated.  The phrase &#8220;I&#8217;m going home to play with the kernel&#8221; was frequently questioned by my boss Jeremy.  I wanted these things to work but was endlessly faffing about trying to make it happen.</p>
<p>Better call Stuart.</p>
<p>&#8220;You should try this new Debian based distribution called Ubuntu&#8221; he said.</p>
<p>So I did, and it just worked.  A box fresh kernel with all the goodies I needed already compiled in and an up-to-date GNOME desktop (I&#8217;d set my allegiances before trying Ubuntu so this was another tick in the box), not forgetting one of the brownest themes known to man.</p>
<p>And that was that.  Ubuntu worked for me and I was immediately a fan.</p>
<p>And here I am today, 10 years later, still running Ubuntu.  My servers run Ubuntu, all the desktops in my house run Ubuntu, I have an Ubuntu powered phone and soon I&#8217;ll have an Ubuntu powered Mycroft with which I&#8217;ll be able to control my Ubuntu powered things while wearing my Ubuntu T shirt and drinking tea (should that be kool-aid?) from my Ubuntu mug.</p>
<p>I salute my Ubuntu brothers and sisters.  Thanks for making all of this possible.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Big Bug Bonanza Ubuntu 16.04 LTS</title>
		<link>/2015/09/14/big-bug-bonanza-16-04-lts/</link>
					<comments>/2015/09/14/big-bug-bonanza-16-04-lts/#comments</comments>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Mon, 14 Sep 2015 15:30:12 +0000</pubDate>
				<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=679</guid>

					<description><![CDATA[The vast majority of Ubuntu desktop users prefer to stick with a long [&#8230;]]]></description>
										<content:encoded><![CDATA[<p>The vast majority of Ubuntu desktop users prefer to stick with a long term support release (<a href="https://wiki.ubuntu.com/LTS">https://wiki.ubuntu.com/LTS</a>) rather than the regular 6 monthly releases, so 16.04 LTS represents the next big upgrade for most Ubuntu users.  16.04 LTS will be running Unity 7 by default as it has done for the last six years and our focus for the Unity 7 stack is fixing bugs which adversely affect the user experience of the desktop.</p>
<p>Over the years the bug lists for Unity 7 and Compiz have grown to become unmanageable.  To make sure we are focusing on the most important issues we have to do some serious tidying up of the bug lists and we need some help.</p>
<p>At the time of writing there are 2680 open bugs for Unity 7 (<a href="https://launchpad.net/ubuntu/+source/unity/+bugs">https://launchpad.net/ubuntu/+source/unity/+bugs</a>) and 1455 for Compiz (<a href="https://launchpad.net/ubuntu/+source/compiz/+bugs">https://launchpad.net/ubuntu/+source/compiz/+bugs</a>) and 322 for nux, our graphical toolkit (<a href="https://launchpad.net/ubuntu/+source/nux/+bugs">https://launchpad.net/ubuntu/+source/nux/+bugs</a>).</p>
<p>We&#8217;re proposing to cut this down to size with the following plan:</p>
<ol>
<li><strong>Close all bugs which relate to an unsupported release of Ubuntu.</strong>  We will do a manual review of the high heat bugs affecting unsupported releases first, but low heat bugs will most likely be closed by a robot.  The rationale is that the majority of these older bugs will have been fixed and that the original reporter is probably no longer affected by the bug and has forgotten to close it.  Plus manually screening each of these bugs cannot be done at this scale in a reasonable timeframe.  There will be some collateral damage which is an unfortunate but unavoidable side-effect.  Sorry if this affects you, but please do re-open the bug against a supported release.</li>
<li><strong>Close all private apport bugs and review public ones with a view to closing them as well.</strong>  Apport is the automated error reporting tool which runs when it detects a crash.  It can open a private bug in Launchpad, private because stack traces might contain sensitive information which shouldn’t be public.  We have <a href="http://errors.ubuntu.com/">errors.ubuntu.com</a> which can monitor crashes and provide a <em>much</em> clearer picture of which crashers are affecting numerous people and which are one-offs.  We will use errors.ubuntu.com instead of trying to triage the 250 or so bugs which fall in to this category.</li>
<li><strong>Manually try to reproduce bugs and flag those which are still a problem.</strong>  This is where we need the most help.  We will create a list of bugs which need to be checked and then ask people to spend a few minutes trying to reproduce a chosen bug on 15.10.  If it’s still a problem then the tester would mark the bug as triaged or add a specific tag, or if it cannot be reproduced then they would mark the bug as Invalid.  This will give us a curated list of real bugs which we can then triage further to assess the impact and priority.  We will work through the triaged list in an agile manner and have regular meetings to review what has been fixed and decide on which bugs to focus on next.  By distributing this problem across many people we can get the job done in a reasonable time scale.</li>
</ol>
<h2>How you can help</h2>
<p>First of all we need help in triaging the bug list.  You don’t need to be a superstar software developer to do this, everyone can help and contribute to Ubuntu.  You will need a <a href="https://launchpad.net/">Launchpad</a> account though.  We will publish a link to a list of bugs in Launchpad for Unity 7 (and in time Compiz &amp; Nux) which we think need manual checking.  The links are available at this wiki page:  <a href="https://wiki.ubuntu.com/BigDesktopBugScrub">https://wiki.ubuntu.com/BigDesktopBugScrub</a></p>
<p>Please choose a bug from this list and try to recreate it in 15.10.  If your main machine isn’t running 15.10 you could set up a virtual machine using VirtualBox.</p>
<ol>
<li><strong>Choose a bug from the list. </strong> The heat metric is a good indication of which bugs are more important to a lot of people.  The list is sorted by heat so selecting one from somewhere near the top is a good starting point.  It’s possible that someone else will be working on the same bug as you so check the comments to see if anyone has added anything recently.</li>
<li><strong>Can you recreate the bug?</strong>  There are a number of possible outcomes when you attempt to recreate the bug.  Listed below are the most common ones.  If you can’t match one of these categories directly, or don&#8217;t know what to do just leave the bug where it is and try a different one.
<ol>
<li><strong>No &#8211; I can’t understand from the report what the problem is</strong>:
<ol>
<li>Add a comment along the lines of:  “Thank you for taking the time to report this bug.  Unfortunately we can’t work out how to recreate this bug from your description.  Please describe the process you go through to trigger this bug and then change the bug status to NEW.  See this page for more information. https://wiki.ubuntu.com/BigDesktopBugScrub”</li>
<li>Set the bug status to <strong>Incomplete</strong></li>
</ol>
</li>
<li><strong>No &#8211; I’ve tried to but it doesn’t seem to be a problem any more</strong>:
<ol>
<li>Add a comment along the lines of: “Thank you for taking the time to report this bug.  We have tried to recreate this on the latest release of Ubuntu and cannot reproduce it.  This bug is being marked as Invalid.  If you believe the problem to still exist in the latest version of Ubuntu please comment on why that is the case and change the bug status to NEW.”</li>
<li>Set the bug status to <strong>Invalid</strong></li>
</ol>
</li>
<li><strong>Yes &#8211; it’s still a problem in 15.10</strong>:
<ol>
<li>Add a comment along the lines of: “As part of the big bug review for 16.04 LTS I have tested this on 15.10 and the bug is still there.”</li>
<li>Mark the bug as <strong>Triaged</strong> or, if you don&#8217;t have permission to do that, add the tag “desktop-bugscrub-triaged”</li>
</ol>
</li>
<li><strong>Yes &#8211; but I don’t think it’s really a bug (perhaps a feature request)</strong>:
<ol>
<li>Add a comment along the lines of: “As part of the big bug review for 16.04 LTS I have tested this on 15.10 and the bug is still there.  I think this is a feature request rather than a bug.”</li>
<li>Mark the bug as “<strong>Opinion</strong>”, or if you don’t have permission to do that, add the tag “desktop-bugscrub-opinion”</li>
</ol>
</li>
</ol>
</li>
<li><strong>Thank you!</strong>  We’re one bug closer to perfection!</li>
<li>Lather, Rinse, Repeat</li>
</ol>
<p>&nbsp;</p>
<h2>What happens next</h2>
<p>Once we have a list of high quality, reproducible bug reports which are affecting many people we can start to chip away at them in a logical manner.  We will be using an Agile-like workflow:</p>
<ol>
<li>Meet at the start of a “<a href="http://scrummethodology.com/scrum-sprint/">sprint</a>” to discuss which of the most important bugs (importance will be decided on a mixture of bug heat and expert knowledge) will be working on during the sprint duration.  We will decide how many of the bugs we think are fixable in that sprint and take them into our backlog.  The backlog will be managed using Trello (<a href="https://trello.com/b/9YvUSYqq/unity-7">https://trello.com/b/9YvUSYqq/unity-7</a>).</li>
<li>The sprint will start and developers will take bugs (Cards) from the backlog to work on.</li>
<li>The card will move to the In Progress colum</li>
<li>If there is a problem the bug will move to the blocked column and these cards will be discussed at regular intervals during the sprint.</li>
<li>Once a bug is fixed it will move to the Review column.  A code review will be done and if everything is OK then the fix will be merged and automatically tested.  If there are problems it will move back to the In Progress column.</li>
<li>At the end of the sprint the fixes will be demonstrated and everyone will have a chance to spot any problems with the fix.  If there is a problem the card will go back into the Backlog for more work next sprint.  If everything is OK then the card is moved to Done and that bug is now fixed.</li>
<li>The next sprint will start and we will go back to step 1.</li>
</ol>
<p>&nbsp;</p>
<p>We will endeavour to do our reviews in a Hangout On Air so that everyone can join to see what progress is being made.  We will also use our IRC channel on Freenode <a href="http://is.gd/ubuntu_desktop_irc">#ubuntu-desktop</a>.</p>
<p>&nbsp;</p>
<h2>Software developers who want to help</h2>
<p>If you are a developer who wants to help fix the code as well as triage bugs please join us on IRC (<a href="http://is.gd/ubuntu_desktop_irc">#ubuntu-desktop on Freenode</a>) and introduce yourself.  We can get you write access to the Trello board and invite you along to the Sprint planning and review meetings.  We&#8217;d love you to get involved.</p>
<h2>Bug Squash Hours</h2>
<p>In order to kick start the process we will be setting aside a few hours a week where a core Unity 7 developer will be available on IRC to help answer questions about bugs and we&#8217;ll be working through the list as well.  Feel free to ask for help or come and join us while we work through the bug list.  Exact schedule will be announced as soon as we know what it is.</p>
<p>&nbsp;</p>
<h2>Ubuntu Online Summit</h2>
<p>We will have a session at UOS to review how the bug triage is going, discuss our tooling and policy on which bugs to auto-close etc.</p>
]]></content:encoded>
					
					<wfw:commentRss>/2015/09/14/big-bug-bonanza-16-04-lts/feed/</wfw:commentRss>
			<slash:comments>6</slash:comments>
		
		
			</item>
		<item>
		<title>Snapping Mosquitto MQTT broker</title>
		<link>/2015/02/04/snapping-mosquitto-mqtt-broker/</link>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Wed, 04 Feb 2015 17:32:44 +0000</pubDate>
				<category><![CDATA[linux]]></category>
		<category><![CDATA[Making the world a better place]]></category>
		<category><![CDATA[RaspberryPi]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=598</guid>

					<description><![CDATA[As part of my ever expanding home automation system I wanted to use [&#8230;]]]></description>
										<content:encoded><![CDATA[<p style="text-align: justify;"><em>As part of my ever expanding home automation system I wanted to use MQTT to publish data on my network. With the release of the Raspberry Pi 2 I can run Ubuntu Core to create a reliable, secure and easily updated server which is a perfect fit for requirements of an MQTT broker and general HA controller. I asked some Ubuntu friends to help me package Mosquitto as a Snap, and in return I would write down how we did it. Here&#8217;s the story&#8230;</em></p>
<p>Start by reading this: <a title="https://developer.ubuntu.com/en/snappy/" href="https://developer.ubuntu.com/en/snappy/">https://developer.ubuntu.com/en/snappy/</a></p>
<p style="text-align: justify;"><span style="text-decoration: underline;">In summary;</span> a Snappy application is secure because it&#8217;s wrapped with AppArmor. It&#8217;s easier to install and upgrade because everything is packaged in a single file and installed to a single location. That location is backed-up before you install a new version, and so if the installation goes wrong you can revert to the previous version easily by copying the original files back (or rather, Snappy will do all of that for you). Simplifying things slightly there are two types of Snappy &#8220;application&#8221;: Apps and Frameworks. Frameworks can extend the OS and provide a mediation layer to access shared resources. Apps are your more traditional top-level items which can use the provided frameworks, or bundle everything they need in to their Snap. This makes things much easier for app providers because they are now in charge &#8211; they can be assured that no library will change underneath them.  This is a huge benefit!</p>
<h2>Let&#8217;s get Mosquitto snapped.</h2>
<h3>1. Install QEMU to run an Ubuntu Core machine</h3>
<p><a title="http://www.ubuntu.com/cloud/tools/snappy#snappy-local" href="http://www.ubuntu.com/cloud/tools/snappy#snappy-local">http://www.ubuntu.com/cloud/tools/snappy#snappy-local</a></p>
<p>First we install the KVM hypervisor:</p>
<pre style="padding-left: 60px;">sudo apt-get install qemu-kvm</pre>
<p>Then check everything is as it should be with:</p>
<pre style="padding-left: 60px;">kvm-ok</pre>
<p>Now download the latest Ubuntu Core image from here: <a title="http://cdimage.ubuntu.com/ubuntu-core/preview/" href="http://cdimage.ubuntu.com/ubuntu-core/preview/">http://cdimage.ubuntu.com/ubuntu-core/preview/</a>  At the time of writing this is the newest x86-64 image: <a title="http://cdimage.ubuntu.com/ubuntu-core/preview/ubuntu-core-alpha-02_amd64-virt.img" href="http://cdimage.ubuntu.com/ubuntu-core/preview/ubuntu-core-alpha-02_amd64-virt.img">http://cdimage.ubuntu.com/ubuntu-core/preview/ubuntu-core-alpha-02_amd64-virt.img</a></p>
<p>Then launch the virtual machine. This command port forwards 8022 on your local machine to 22 on the virtual machine, so you can SSH to port 8022 on localhost and actually connect to the Ubuntu Core machine. It gives the Core machine 512MB of RAM, nicely achievable on a modest budget (The Pi2 has 1 GB).  We also forward port 1883 from to the VM, which will allow us to connect to the Mosquitto server on our VM once it&#8217;s all installed.</p>
<pre style="padding-left: 60px;">kvm -m 512 -redir :8022::22 -redir :1883::1883 &lt;vm image file&gt;</pre>
<p>Once it&#8217;s booted you can connect to it with SSH. The username and password are &#8220;ubuntu&#8221;.</p>
<pre style="padding-left: 60px;">ssh -p 8022 ubuntu@localhost</pre>
<p>To make things a bit easier, why not use key authentication? On your host machine:</p>
<pre style="padding-left: 60px;">ssh-copy-id -p 8022 ubuntu@localhost</pre>
<p>We should also upgrade our Ubuntu Core VM before we start.  SSH in to your box and run:</p>
<pre style="padding-left: 60px;">sudo snappy update
sudo reboot</pre>
<h3>2. Build Mosquitto in the right way</h3>
<p>Back on your host (not the virtual machine you just created above) create some directories to hold the code and download the latest stable source and the build dependencies for Mosquitto:</p>
<pre style="padding-left: 60px;">sudo apt-get install build-essential cmake
sudo apt-get build-dep mosquitto</pre>
<pre style="padding-left: 60px;">mkdir -p mosquitto/install mosquitto/build</pre>
<pre style="padding-left: 60px;">cd mosquitto</pre>
<pre style="padding-left: 60px;">wget http://mosquitto.org/files/source/mosquitto-1.3.5.tar.gz</pre>
<pre style="padding-left: 60px;">tar xvzf mosquitto-1.3.5.tar.gz</pre>
<pre style="padding-left: 60px;">cd build</pre>
<p>Time to build Mosquitto.  Before you run the commands below, a bit of background information.  The cmake line will force cmake to install the binaries to the location specified with INSTALL_PREFIX, rather than /usr/local.  This is required to bundle all of the binaries and other files to the &#8220;install&#8221; directory we created above, making it possible to package as a Snappy.</p>
<pre style="padding-left: 60px;">cmake -DCMAKE_INSTALL_PREFIX=`readlink -f ../install/` ../mosquitto-1.3.5</pre>
<pre style="padding-left: 60px;">make -j`nproc`

make install</pre>
<p>nproc spits out the number of processor cores you have, so the make line above will use as many processor cores as you have available.  It&#8217;s not required, and for Mosquitto which is fairly small it&#8217;s not worth worrying about, but for a bigger job this is quite handy.</p>
<p>If you look in the &#8220;../install&#8221; directory you&#8217;ll see a familiar structure containing all the goodies needed by Mosquitto.</p>
<h3>3. Find the libraries needed and copy them in to your Snappy project</h3>
<p>Change in to the install/lib directory and use ldd to display the linked libraries for the two main .so files:</p>
<pre style="padding-left: 60px;">ldd lib/libmosquitto.so.1.3.5 lib/libmosquittopp.so.1.3.5 | grep '=&gt;' | awk '{ print $1 }' | sort | uniq</pre>
<p>This uses ldd to show the libraries required by Mosquitto, and then sorts them in to a nice list. You&#8217;ll see something like this:</p>
<pre style="padding-left: 60px;">libcares.so.2
libcrypto.so.1.0.0
libc.so.6
libdl.so.2
libgcc_s.so.1
libmosquitto.so.1
libm.so.6
libpthread.so.0
librt.so.1
libssl.so.1.0.0
libstdc++.so.6
linux-vdso.so.1</pre>
<p>Now, on the Ubuntu Core machine we can run this little script:</p>
<pre style="padding-left: 60px;">for i in `cat`; do find /lib /usr/lib -name $i; done</pre>
<p>Copy the list from the previous command to the clipboard and then paste it in to terminal where this command is running and hit Ctrl-D to submit the list.  The script will then search Ubuntu Core for the libraries required.  If it finds them they will be displayed, if it doesn&#8217;t then they are not available in Ubuntu Core by default and will need to be included in your Snappy package.</p>
<p><code>linux-vdso</code> is the Linux kernel and is available on every Linux system by default, so we don&#8217;t need to provide that specifically.</p>
<p><code>libssl, libcrypto, libpthread, librt, libc </code>and<code> libdl</code> are all available in Ubuntu Core by default &#8211; so we don&#8217;t need those either.</p>
<p>That leaves just <code>libcares</code> to be copied in to our package.</p>
<pre style="padding-left: 60px;"> cp /usr/lib/x86_64-linux-gnu/libcares.so.2.1.0 .</pre>
<p>We should already be in the &#8216;lib&#8217; directory, hence the &#8216;.&#8217; above.  We are copying libcares in to the lib directory of our Snap, and when we run the Snap we will pass in the library path to make sure Mosquitto can find it.  More on this later.</p>
<h3>4. Add the meta data required for the Snappy package</h3>
<p>Reference: <a title=" https://developer.ubuntu.com/en/snappy/guides/packaging-format-apps/" href="https://developer.ubuntu.com/en/snappy/guides/packaging-format-apps/">https://developer.ubuntu.com/en/snappy/guides/packaging-format-apps/</a></p>
<p>Create the meta data directory inside the install directory (change to the install directory, it should just be cd ..):</p>
<pre style="padding-left: 60px;">mkdir meta</pre>
<p>Create the package.yaml file:</p>
<pre style="padding-left: 60px;">nano meta/package.yaml</pre>
<p>And this is what we&#8217;re putting in it:</p>
<pre style="padding-left: 60px;">name: mosquitto.willcooke
architecture: amd64
version: 1.3.5
icon:
services:
 - name: mosquitto
 start: ./sbin/mosquitto.sh
ports:
 required: 1883</pre>
<p>Information about these fields and what they mean is available in the reference linked to above, but they are easily understandable.  A comment on the name though, you need to append .&lt;yournamespace&gt; where your namespace is as you select in your Ubuntu myapps account.  One thing to mention, you can see that to start our Snap we are calling a shell script.  This allows us to pass in extra options to Mosquitto when it runs.</p>
<p>Next we need to create a readme file:</p>
<pre style="padding-left: 60px;">nano meta/readme.md</pre>
<p>This file needs to contain at least a couple of non-blank lines.  Here&#8217;s what we put in it:</p>
<pre style="padding-left: 60px;">This is a Snappy package for Mosquitto MQTT broker.</pre>
<pre style="padding-left: 60px;">Information about Mosquitto is available here:  http://mosquitto.org/</pre>
<pre style="padding-left: 60px;">Information about MQTT is available here: http://mqtt.org/</pre>
<p>We also need to configure our Mosquitto server, by editing the conf file.  Most of the settings can be left as default, so we will create a new conf file with only the bits in we need.</p>
<pre style="padding-left: 60px;">mv etc/mosquitto/mosquitto.conf etc/mosquitto/mosquitto.conf.ori</pre>
<pre style="padding-left: 60px;">nano etc/mosquitto/mosquitto.conf</pre>
<p>Add these two lines:</p>
<pre style="padding-left: 60px;">user root
persistence_location /var/apps/mosquitto/current/</pre>
<p>We need to change this to run as root.  Since our Snap will be confined there is no risk here.  I expect the ability to run as non-root users when using Snappy will be improved, but really it&#8217;s not necessary.</p>
<p>We also need to add a small shell script to start Mosquitto with the right options.  Create a file in install/sbin called mosquitto.sh:</p>
<pre style="padding-left: 60px;">nano sbin/mosquitto.sh</pre>
<p>And add this:</p>
<pre style="padding-left: 30px;">#!/bin/sh
LD_LIBRARY_PATH=./lib:$LD_LIBRARY_PATH exec ./sbin/mosquitto -c etc/mosquitto/mosquitto.conf</pre>
<p>We are specifying where to find the extra libraries we require and where to find the conf file.  Make that file executable:</p>
<pre style="padding-left: 60px;">chmod +x sbin/mosquitto.sh</pre>
<h3>5. Build your Snappy package</h3>
<p>Add the Snappy PPA to get the build tools, and then install them:</p>
<pre style="padding-left: 60px;">sudo add-apt-repository ppa:snappy-dev/beta
sudo apt-get update
sudo apt-get dist-upgrade
sudo apt install snappy-tools</pre>
<p>In your <code>install</code> directory run:</p>
<pre style="padding-left: 60px;">snappy build .</pre>
<p>If you see an error about ImportError: No module named &#8216;click.repository&#8217; then you likely have a clash between the Click library version in the SDK team PPA and the version in the Snappy PPA.  This will be fixed soon, but in the meantime I would suggest installing ppa-purge via apt-get and then running <code>sudo ppa-purge ppa:ubuntu-sdk-team/ppa</code>.</p>
<p>If you see an error about &#8220;expected &lt;block end&gt;&#8221; in the package.yaml check the whitespace in the file.  It&#8217;s likely a copy and paste error.</p>
<h3>6. Install your Snappy package</h3>
<p>Once you have your .snap file you can install it to your virtual machine like this:</p>
<pre>snappy-remote --url=ssh://localhost:8022 install ./mosquitto_1.3.5_amd64.snap</pre>
<p>&nbsp;</p>
<h3>7. Test your Snappy package</h3>
<p>If everything has gone to plan Mosquitto should now be running on your virtual machine.  In order to test you&#8217;ll need to write a test Publisher and Subscriber.  I used the Python Paho library.</p>
<p>Here&#8217;s an example Publisher:</p>
<pre style="padding-left: 60px;">#!/usr/bin/python</pre>
<pre style="padding-left: 60px;">import paho.mqtt.client as mqtt
from datetime import datetime
from time import sleep</pre>
<pre style="padding-left: 60px;">def send_mqtt(topic, message):
 log("Sending MQTT")
 log("Topic: "+topic)
 log("Message: "+message)
 mqttc.reconnect()
 mqttc.publish(topic, message)
 mqttc.loop() 
 mqttc.disconnect()</pre>
<pre style="padding-left: 60px;">print "Time server starting up...."
mqttc = mqtt.Client("python_pub")
mqttc.connect("localhost", 1883)</pre>
<pre style="padding-left: 60px;">while True:
 tstr = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
 send_mqtt("/information/time",tstr)
 sleep(10)</pre>
<p>And here&#8217;s an example Subscriber:</p>
<pre style="padding-left: 60px;">#!/usr/bin/python</pre>
<pre style="padding-left: 60px;">import paho.mqtt.client as mqtt
import datetime</pre>
<pre style="padding-left: 60px;">def on_connect(client, userdata, rc):
 print "Connected with result code "+str(rc)
 client.subscribe("#")
 
def on_message(client, userdata, msg):
 print "Topic: ", msg.topic+'\nMessage: '+str(msg.payload)
 
 
client = mqtt.Client()
client.on_connect = on_connect
client.on_message = on_message</pre>
<pre style="padding-left: 60px;">client.connect("localhost", 1883, 60)</pre>
<pre style="padding-left: 60px;">client.loop_forever()</pre>
<p>&nbsp;</p>
<h2>What&#8217;s next?</h2>
<p>We&#8217;ve built a Snappy package for amd64 (or whatever your native architecture is), but we really need to be cross-architecture to give people the best choice of platform on which to use the package.  This involves cross compiling, which can be tricky to put it mildly.</p>
<p>I spoke to <a title="https://plus.google.com/+AlexanderSack/posts" href="https://plus.google.com/+AlexanderSack/posts">Alexander Sack</a>, the Director of Ubuntu Core, and asked what was coming next for Snappy and I was very excited to hear about easier cross-compilation methods as well as a cool script to help automate gathering the libraries in to your package.  I&#8217;ll find out more about these and follow up with another post about</p>
<h2>Special Thanks</h2>
<p>A huge &#8220;Thank You!&#8221; to <a title="https://plus.google.com/113078171667682980510/posts" href="https://plus.google.com/113078171667682980510/posts">Saviq</a> and <a title="https://www.google.com/+DidierRoche" href="https://www.google.com/+DidierRoche">Didrocks</a> for doing the actual work and letting me watch.</p>
<p>&nbsp;</p>
<h2>Where to get Snappy Mosquitto</h2>
<p>amd64 version:  <a title="https://myapps.developer.ubuntu.com/dev/click-apps/ubuntu/1500/" href="https://myapps.developer.ubuntu.com/dev/click-apps/ubuntu/1500/">https://myapps.developer.ubuntu.com/dev/click-apps/ubuntu/1500/</a><br />
armhf version: <a title="https://myapps.developer.ubuntu.com/dev/click-apps/ubuntu/1502/" href="https://myapps.developer.ubuntu.com/dev/click-apps/ubuntu/1502/">https://myapps.developer.ubuntu.com/dev/click-apps/ubuntu/1502/</a> (please note, I haven&#8217;t been able to test the ARM version because of a lack of hardware.  If it doesn&#8217;t work let me know and I can fix it.)</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Recording screencasts from the Unity 8 Desktop Preview</title>
		<link>/2014/08/28/recording-screencasts-from-the-unity-8-desktop-preview/</link>
		
		<dc:creator><![CDATA[will]]></dc:creator>
		<pubDate>Thu, 28 Aug 2014 12:33:10 +0000</pubDate>
				<category><![CDATA[linux]]></category>
		<category><![CDATA[Making the world a better place]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=590</guid>

					<description><![CDATA[Obtaining and running Unity 8 Desktop Preview If you like playing with new [&#8230;]]]></description>
										<content:encoded><![CDATA[<h1>Obtaining and running Unity 8 Desktop Preview</h1>
<p>If you like playing with new toys you might have already downloaded and tried the Unity 8 Desktop Preview (available here:  <a href="http://cdimage.ubuntu.com/ubuntu-desktop-next/daily-live/current/" target="_blank" rel="noopener noreferrer">http://cdimage.ubuntu.com/ubuntu-desktop-next/daily-live/current/</a>)</p>
<p>If you haven&#8217;t, you should take it for a spin.  If you have an Intel graphics everything should be fine and dandy, if not YMMV at the moment.</p>
<ol>
<li>Download the ISO</li>
<li>Find a spare &gt;1GB USB thumb drive</li>
<li>Run &#8220;disks&#8221; via the dash</li>
<li>Highlight your USB drive and from the cog icon on the right choose &#8220;Restore Disk Image&#8230;&#8221;</li>
<li>Select your ISO and &#8220;Start Restoring&#8221;  &#8211; this will of course erase everything else on your USB stick</li>
<li>Done</li>
</ol>
<p>You can now boot from your USB stick and have a play with Unity 8.  Right now you&#8217;ll be seeing the Phone view of Unity 8, but that will all be changing in time.</p>
<h1>Capturing a screencast</h1>
<p>Once you&#8217;ve got everything up and running you might like to make a few screencasts, so how do you do it?  Well, the Mir developers have provided us with the mirscreencast tool so let&#8217;s use that:</p>
<p>Switch to tty1 (ctrl+alt+f1) and log in and run:</p>
<pre>mirscreencast --file &lt;output file&gt; -m /run/lightdm-mir-0</pre>
<p>Then switch back to tty8 (ctrl-alt-f8) and use Unity.</p>
<p>Your file will now be filling up FAST.  Mirscreencast will be trying to write every raw frame to that file, probably at a rate of 60 frames a second.  To kill mirscreencast I first hit ctrl-z and then:</p>
<pre> pkill -9 mirscreencast</pre>
<p>but there is probably a better way.</p>
<h1>Capturing a better screencast</h1>
<p>There are a few command line options for mirscreencast which will can help us shrink the file size a bit:</p>
<pre>mirscreencast --file &lt;output file&gt; -m /run/lightdm-mir-0 -s 683 384 -n 3600</pre>
<p>The option &#8220;-s&#8221; will resize the captured frames.  Note that 683 384 is exactly half my native resolution, so you will need to adjust this to your display.</p>
<p>The option &#8220;-n&#8221; will capture n frames and then stop.  At 60 frames a second, 3600 frames is one minute.  If you use -n then mirscreencast will exit gracefully at the end.</p>
<h1>Playing back your screencast</h1>
<p>I am lucky enough to have a spare machine with a touch screen just for running Unity 8 on (<a href="http://www.dell.com/uk/dfh/p/inspiron-11-3137/pd" target="_blank" rel="noopener noreferrer">http://www.dell.com/uk/dfh/p/inspiron-11-3137/pd</a>) so I SCP the raw video file on to my main machine for playback and editing.</p>
<p>I use mplayer for most of my video playback and encoding needs and it will happily play the raw video file, but it needs a few pointers:</p>
<pre>mplayer -demuxer rawvideo -rawvideo fps=60:w=683:h=384:format=bgra &lt;filename&gt;</pre>
<p>or, to convert the raw file into something which you can edit in OpenShot try this:</p>
<pre>mencoder -demuxer rawvideo -rawvideo fps=60:w=683:h=384:format=bgra -ovc x264 -o &lt;output filename&gt; &lt;filename&gt;</pre>
<p>And then you can edit and upload the processed file.  When I export from OpenShot I use the &#8220;Web&#8221; profile, then target &#8220;YouTube-HD&#8221;, &#8220;HD 720p 29.97 fps&#8221; &#8220;Med&#8221; &#8211; it&#8217;s a bit overly compressed, but it looks OK.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
